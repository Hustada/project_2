{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 5:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
      "First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 1 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 7 Name: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2afb758ac8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 5\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return np.array((x)/(255))\n",
    "    print(normalize)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], name = 'x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name = 'y')\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 32, 32, 5), dtype=float32)\n",
      "10\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    weights = {\n",
    "    'wc1': tf.Variable(tf.truncated_normal(\n",
    "    [*conv_ksize, int(x_tensor.shape[3]), conv_num_outputs],\n",
    "    mean=0.0,\n",
    "    stddev=0.01,\n",
    "    dtype=tf.float32))}\n",
    "    \n",
    "    biases = {\n",
    "        'bc1': tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    }\n",
    "    \n",
    "    layer = tf.nn.conv2d(tf.cast(x_tensor, tf.float32),weights['wc1'],[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    layer = tf.nn.bias_add(layer, biases['bc1'])\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    layer = tf.nn.max_pool(layer,\n",
    "                          ksize=[1, *pool_ksize, 1],\n",
    "                          strides=[1, *pool_strides, 1],\n",
    "                          padding='SAME')\n",
    "    \n",
    "    print(conv_ksize)\n",
    "    print(x_tensor)\n",
    "    print(conv_num_outputs)\n",
    "    return layer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(?, 10, 30, 6), dtype=float32)\n",
      "?\n",
      "10\n",
      "30\n",
      "6\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    print(x_tensor)\n",
    "    # TODO: Implement Function\n",
    "    #if input shape is [batch_size, W, H, D] then output should be [batch_size, W*H*D]. \n",
    "    #In order to achieve this you can use tf.reshape. \n",
    "    #Here [-1, W*H*D] means [first_dimension, second_dimension].\n",
    "    batch_size = x_tensor.shape[0]\n",
    "    width = x_tensor.shape[1]\n",
    "    height = x_tensor.shape[2]\n",
    "    depth = x_tensor.shape[3]\n",
    "    print(batch_size)\n",
    "    print(width)\n",
    "    print(height)\n",
    "    print(depth)\n",
    "    \n",
    "    #flat_image_size = width * height * depth\n",
    "    #print(flat_image_size)\n",
    "    #return tf.reshape(x_tensor, [-1, flat_image_size])\n",
    "    \n",
    "    #simpler working approach for now\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    fully_conn_weight = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]),num_outputs],mean=0.0,stddev = 0.05))\n",
    "    fully_conn_bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    fully_conn_layer = tf.add(tf.matmul(x_tensor, fully_conn_weight), fully_conn_bias)\n",
    "    fully_conn_layer = tf.nn.relu(fully_conn_layer)\n",
    "    return fully_conn_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    output_weight = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), num_outputs],mean=0.0,stddev = 0.01))\n",
    "    output_bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    \n",
    "    out = tf.add(tf.matmul(x_tensor, output_weight), output_bias)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "Tensor(\"x:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "16\n",
      "(3, 3)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "16\n",
      "(3, 3)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "16\n",
      "Tensor(\"MaxPool_2:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "?\n",
      "32\n",
      "32\n",
      "16\n",
      "(3, 3)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "16\n",
      "(3, 3)\n",
      "Tensor(\"MaxPool_3:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "16\n",
      "(3, 3)\n",
      "Tensor(\"MaxPool_4:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "16\n",
      "Tensor(\"MaxPool_5:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "?\n",
      "32\n",
      "32\n",
      "16\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    x_tensor = x\n",
    "    conv_ksize = (3,3) \n",
    "    conv_num_outputs = 16\n",
    "    conv_strides = (1,1)\n",
    "    pool_ksize = (3,3)\n",
    "    pool_strides = (1,1)\n",
    "    num_outputs = 10\n",
    "    \n",
    "    conv = conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize,\n",
    "                        conv_strides, pool_ksize, pool_strides)\n",
    "    conv2 = conv2d_maxpool(conv, conv_num_outputs, conv_ksize, conv_strides,\n",
    "                         pool_ksize, pool_strides)\n",
    "    conv3 = conv2d_maxpool(conv2, conv_num_outputs, conv_ksize, conv_strides,\n",
    "                         pool_ksize, pool_strides)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "    flat = flatten(conv3)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    fully_conn1 = fully_conn(flat, 512)\n",
    "    fully_conn1 = tf.nn.dropout(fully_conn1, keep_prob)\n",
    "    fully_conn2 = fully_conn(fully_conn1, 512)\n",
    "    fully_conn2 = tf.nn.dropout(fully_conn2, keep_prob)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    output_data = output(fully_conn1, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x:feature_batch,\n",
    "        y:label_batch,\n",
    "        keep_prob: keep_probability\n",
    "    })\n",
    "        \n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Accuracy: {:.6f}'.format(loss,valid_acc))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 64\n",
    "batch_size = 128\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2360 Accuracy: 0.244800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.1496 Accuracy: 0.291600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.0910 Accuracy: 0.308800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.0526 Accuracy: 0.316800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9990 Accuracy: 0.335800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.9675 Accuracy: 0.342000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.9109 Accuracy: 0.355400\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.8323 Accuracy: 0.361400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.7545 Accuracy: 0.374800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.7146 Accuracy: 0.382800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.6682 Accuracy: 0.390200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.6085 Accuracy: 0.392400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.5630 Accuracy: 0.393000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.4836 Accuracy: 0.400800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.4017 Accuracy: 0.400200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.3287 Accuracy: 0.406800\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.2679 Accuracy: 0.393800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.2028 Accuracy: 0.404200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.1578 Accuracy: 0.406000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.2247 Accuracy: 0.388400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.1265 Accuracy: 0.394800\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.1118 Accuracy: 0.386600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.9607 Accuracy: 0.398000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.8877 Accuracy: 0.406000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.8120 Accuracy: 0.398200\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.8477 Accuracy: 0.391400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.7131 Accuracy: 0.396600\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.6837 Accuracy: 0.390600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.7183 Accuracy: 0.383600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.5451 Accuracy: 0.389600\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.6887 Accuracy: 0.382200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.5272 Accuracy: 0.395600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.5289 Accuracy: 0.378200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.4840 Accuracy: 0.381800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.4259 Accuracy: 0.387600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.3673 Accuracy: 0.399200\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.3698 Accuracy: 0.397200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.3382 Accuracy: 0.387400\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.2877 Accuracy: 0.399800\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.2808 Accuracy: 0.390200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.3249 Accuracy: 0.403200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.3402 Accuracy: 0.389800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.3128 Accuracy: 0.387000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.2698 Accuracy: 0.382200\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.2325 Accuracy: 0.389800\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.2108 Accuracy: 0.397000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.1962 Accuracy: 0.399400\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.1635 Accuracy: 0.394800\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.1673 Accuracy: 0.391200\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.1288 Accuracy: 0.392800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.1162 Accuracy: 0.394000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.1417 Accuracy: 0.388200\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.1219 Accuracy: 0.390600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.1423 Accuracy: 0.382000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.0964 Accuracy: 0.388800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.0940 Accuracy: 0.383400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.0855 Accuracy: 0.389600\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.0947 Accuracy: 0.384000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.0965 Accuracy: 0.387200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.0852 Accuracy: 0.391400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.0812 Accuracy: 0.386600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.0929 Accuracy: 0.386600\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.0677 Accuracy: 0.385000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.1016 Accuracy: 0.384800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1926 Accuracy: 0.248200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.8865 Accuracy: 0.299800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.6430 Accuracy: 0.299400\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.6316 Accuracy: 0.371600\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.7061 Accuracy: 0.383400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.9405 Accuracy: 0.413800\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.7491 Accuracy: 0.410200\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.3877 Accuracy: 0.423800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.5166 Accuracy: 0.436800\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.6714 Accuracy: 0.427000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.7661 Accuracy: 0.442400\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.6273 Accuracy: 0.433600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.3000 Accuracy: 0.444400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.4596 Accuracy: 0.447000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.6188 Accuracy: 0.446000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.6557 Accuracy: 0.464400\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.4996 Accuracy: 0.457000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.2660 Accuracy: 0.465200\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.4222 Accuracy: 0.465200\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.5548 Accuracy: 0.465600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.6026 Accuracy: 0.476400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.4438 Accuracy: 0.467000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.2293 Accuracy: 0.468800\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.3909 Accuracy: 0.456400\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.4824 Accuracy: 0.479600\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.5515 Accuracy: 0.481800\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.4162 Accuracy: 0.489000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.1818 Accuracy: 0.487000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.3546 Accuracy: 0.471200\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.4553 Accuracy: 0.482000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.4676 Accuracy: 0.485800\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.3297 Accuracy: 0.475400\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.2126 Accuracy: 0.485600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.3377 Accuracy: 0.477400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.4338 Accuracy: 0.490000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.3832 Accuracy: 0.482600\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.3627 Accuracy: 0.487400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.1632 Accuracy: 0.492400\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.3285 Accuracy: 0.492400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.4057 Accuracy: 0.494800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.3928 Accuracy: 0.497800\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.3385 Accuracy: 0.494000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.1090 Accuracy: 0.494400\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.2666 Accuracy: 0.487600\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.3419 Accuracy: 0.499200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.3161 Accuracy: 0.495800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.2796 Accuracy: 0.499800\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.1087 Accuracy: 0.503400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.2554 Accuracy: 0.489600\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.2951 Accuracy: 0.500800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.3544 Accuracy: 0.499000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.2730 Accuracy: 0.503000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.1110 Accuracy: 0.507600\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.2328 Accuracy: 0.492800\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.2405 Accuracy: 0.507200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.3371 Accuracy: 0.493600\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.1959 Accuracy: 0.498000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.0935 Accuracy: 0.510800\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.1866 Accuracy: 0.499200\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.1981 Accuracy: 0.506400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.2671 Accuracy: 0.512000\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.1473 Accuracy: 0.504200\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.0929 Accuracy: 0.511400\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.1827 Accuracy: 0.501200\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.2178 Accuracy: 0.510400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.2498 Accuracy: 0.506600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.1559 Accuracy: 0.507800\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.0443 Accuracy: 0.512800\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.1001 Accuracy: 0.505800\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.1945 Accuracy: 0.510600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.2329 Accuracy: 0.507800\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.0983 Accuracy: 0.506800\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.0326 Accuracy: 0.516200\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.1054 Accuracy: 0.515200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.1590 Accuracy: 0.513200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.2213 Accuracy: 0.509800\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.0818 Accuracy: 0.513400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.0490 Accuracy: 0.515800\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.0298 Accuracy: 0.520400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.1414 Accuracy: 0.521000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.2214 Accuracy: 0.509200\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.1029 Accuracy: 0.524000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.0308 Accuracy: 0.509000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.0211 Accuracy: 0.516800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.1278 Accuracy: 0.529400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.1677 Accuracy: 0.524400\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.0628 Accuracy: 0.514600\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.9655 Accuracy: 0.515800\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.0082 Accuracy: 0.519400\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.0878 Accuracy: 0.528200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.1668 Accuracy: 0.523800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.0906 Accuracy: 0.515600\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.9618 Accuracy: 0.517400\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.9970 Accuracy: 0.527400\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.0488 Accuracy: 0.533200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.1264 Accuracy: 0.531000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.0534 Accuracy: 0.511800\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.9601 Accuracy: 0.517000\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.9415 Accuracy: 0.538400\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.0455 Accuracy: 0.532000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.1475 Accuracy: 0.514200\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.0473 Accuracy: 0.526400\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.9908 Accuracy: 0.515200\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.9623 Accuracy: 0.529600\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.9682 Accuracy: 0.535600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.1276 Accuracy: 0.526800\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.0558 Accuracy: 0.527000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.9440 Accuracy: 0.529800\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.9475 Accuracy: 0.533600\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.9419 Accuracy: 0.535600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.1094 Accuracy: 0.533400\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.9533 Accuracy: 0.528200\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.9386 Accuracy: 0.533400\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.8708 Accuracy: 0.540200\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.9501 Accuracy: 0.543400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.0295 Accuracy: 0.547400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.9578 Accuracy: 0.531000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.9171 Accuracy: 0.538200\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.8904 Accuracy: 0.539200\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.8468 Accuracy: 0.544600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.0020 Accuracy: 0.534600\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.9598 Accuracy: 0.537000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.9020 Accuracy: 0.528400\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.8061 Accuracy: 0.536800\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.8523 Accuracy: 0.538600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.9576 Accuracy: 0.544200\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.9794 Accuracy: 0.534200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.8912 Accuracy: 0.527800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.8163 Accuracy: 0.527800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.8072 Accuracy: 0.542800\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.9081 Accuracy: 0.546000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.9186 Accuracy: 0.538600\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.8738 Accuracy: 0.528400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.7647 Accuracy: 0.539200\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.7507 Accuracy: 0.540400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.8948 Accuracy: 0.548600\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.9085 Accuracy: 0.539000\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.8814 Accuracy: 0.533800\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.7880 Accuracy: 0.531800\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.6953 Accuracy: 0.550000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.8444 Accuracy: 0.545400\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.8453 Accuracy: 0.542800\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.8441 Accuracy: 0.537200\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.7637 Accuracy: 0.544000\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.6849 Accuracy: 0.555600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.8658 Accuracy: 0.552600\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.8108 Accuracy: 0.532800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.8459 Accuracy: 0.543800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.7628 Accuracy: 0.537200\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.6491 Accuracy: 0.557000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.8102 Accuracy: 0.551800\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.7671 Accuracy: 0.525800\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.8602 Accuracy: 0.543600\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.7604 Accuracy: 0.541800\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.5904 Accuracy: 0.550200\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.8093 Accuracy: 0.546600\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.7805 Accuracy: 0.524200\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.8180 Accuracy: 0.546000\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.6815 Accuracy: 0.541800\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.6430 Accuracy: 0.550800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.7983 Accuracy: 0.532800\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.7106 Accuracy: 0.534400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.8620 Accuracy: 0.545000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.6459 Accuracy: 0.552000\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.6270 Accuracy: 0.560200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.7827 Accuracy: 0.537400\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.6830 Accuracy: 0.547600\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.8236 Accuracy: 0.551600\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.6526 Accuracy: 0.541800\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.5669 Accuracy: 0.552000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.7529 Accuracy: 0.540400\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.6784 Accuracy: 0.547600\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.7910 Accuracy: 0.556800\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.6391 Accuracy: 0.556800\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.5384 Accuracy: 0.549400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.6819 Accuracy: 0.546600\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.6367 Accuracy: 0.546800\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.7783 Accuracy: 0.556600\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.6225 Accuracy: 0.557000\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.5287 Accuracy: 0.551600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.6910 Accuracy: 0.536400\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.5993 Accuracy: 0.545600\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.7441 Accuracy: 0.551800\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.6179 Accuracy: 0.549000\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.5215 Accuracy: 0.555000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.6406 Accuracy: 0.550400\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.5645 Accuracy: 0.549400\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.7856 Accuracy: 0.536000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.5883 Accuracy: 0.552600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.4983 Accuracy: 0.550600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.6302 Accuracy: 0.550400\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.5333 Accuracy: 0.538800\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.7386 Accuracy: 0.541200\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.5773 Accuracy: 0.551200\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.4990 Accuracy: 0.562400\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.5731 Accuracy: 0.556800\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.5544 Accuracy: 0.538800\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.7071 Accuracy: 0.561800\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.5525 Accuracy: 0.562200\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.4383 Accuracy: 0.557000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.5699 Accuracy: 0.551400\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.5199 Accuracy: 0.551200\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.7140 Accuracy: 0.545200\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.5288 Accuracy: 0.553200\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.4582 Accuracy: 0.547400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.5738 Accuracy: 0.556200\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.4867 Accuracy: 0.555800\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.6925 Accuracy: 0.562000\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.5022 Accuracy: 0.554600\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.4088 Accuracy: 0.557800\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.5802 Accuracy: 0.544800\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.5182 Accuracy: 0.554400\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.6305 Accuracy: 0.556400\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.4803 Accuracy: 0.555400\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.4075 Accuracy: 0.552800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.5428 Accuracy: 0.551800\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.5263 Accuracy: 0.552200\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.6212 Accuracy: 0.556400\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.4812 Accuracy: 0.552200\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.3719 Accuracy: 0.553800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.5420 Accuracy: 0.546200\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.4861 Accuracy: 0.552000\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.5839 Accuracy: 0.556400\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.4436 Accuracy: 0.551000\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.3623 Accuracy: 0.547600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.4685 Accuracy: 0.566000\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.4361 Accuracy: 0.556800\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.5981 Accuracy: 0.554800\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.4566 Accuracy: 0.556600\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.3361 Accuracy: 0.554800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.4236 Accuracy: 0.559600\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.4319 Accuracy: 0.552800\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.5357 Accuracy: 0.549800\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.4211 Accuracy: 0.557000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.3480 Accuracy: 0.556800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.4624 Accuracy: 0.561000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.4316 Accuracy: 0.548200\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.5112 Accuracy: 0.550600\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.3962 Accuracy: 0.554800\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.3141 Accuracy: 0.548800\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.3777 Accuracy: 0.558000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.4402 Accuracy: 0.559200\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.5013 Accuracy: 0.554200\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.3944 Accuracy: 0.561200\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.3345 Accuracy: 0.549800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.3788 Accuracy: 0.554000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.3904 Accuracy: 0.548400\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.4691 Accuracy: 0.549200\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.3669 Accuracy: 0.553000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.2946 Accuracy: 0.555000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.3415 Accuracy: 0.556400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.3357 Accuracy: 0.546600\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.4643 Accuracy: 0.548800\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     0.3762 Accuracy: 0.554400\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     0.3069 Accuracy: 0.553000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.3601 Accuracy: 0.556200\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.2947 Accuracy: 0.542200\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.4164 Accuracy: 0.550600\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     0.3535 Accuracy: 0.554800\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     0.2809 Accuracy: 0.558600\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.3675 Accuracy: 0.556800\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.2867 Accuracy: 0.547600\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.4518 Accuracy: 0.550800\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     0.3587 Accuracy: 0.553400\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     0.2831 Accuracy: 0.559600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.3313 Accuracy: 0.557800\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.2956 Accuracy: 0.548000\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.4314 Accuracy: 0.544800\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     0.3183 Accuracy: 0.551400\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     0.2552 Accuracy: 0.556600\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.3535 Accuracy: 0.556600\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.2801 Accuracy: 0.556800\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.4164 Accuracy: 0.539600\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     0.2911 Accuracy: 0.547000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     0.2473 Accuracy: 0.554800\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.3803 Accuracy: 0.555400\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.2917 Accuracy: 0.543200\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.4126 Accuracy: 0.536800\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.3595 Accuracy: 0.531000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     0.2928 Accuracy: 0.551200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.3774 Accuracy: 0.552800\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.2895 Accuracy: 0.552400\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.3938 Accuracy: 0.540600\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     0.3287 Accuracy: 0.534200\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     0.2531 Accuracy: 0.556400\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.3706 Accuracy: 0.554400\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.2494 Accuracy: 0.556200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.3963 Accuracy: 0.531200\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     0.3256 Accuracy: 0.523800\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     0.2949 Accuracy: 0.556000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.3743 Accuracy: 0.555000\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.2317 Accuracy: 0.546600\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.4080 Accuracy: 0.530200\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     0.2932 Accuracy: 0.538000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     0.2475 Accuracy: 0.558200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.3142 Accuracy: 0.553000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.2701 Accuracy: 0.550600\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.3723 Accuracy: 0.533000\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.2693 Accuracy: 0.554800\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     0.2391 Accuracy: 0.554400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.2763 Accuracy: 0.558000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.2258 Accuracy: 0.554000\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.3466 Accuracy: 0.540600\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.2797 Accuracy: 0.549000\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     0.2217 Accuracy: 0.555600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.2765 Accuracy: 0.554800\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.2044 Accuracy: 0.551200\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.3522 Accuracy: 0.540600\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.3010 Accuracy: 0.541200\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     0.2028 Accuracy: 0.556800\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.2970 Accuracy: 0.556000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.2177 Accuracy: 0.552600\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.3007 Accuracy: 0.544400\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.2905 Accuracy: 0.550200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     0.2218 Accuracy: 0.556000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.2557 Accuracy: 0.548600\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.2098 Accuracy: 0.554800\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.2988 Accuracy: 0.538000\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.2521 Accuracy: 0.551000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.1961 Accuracy: 0.560600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.560818829113924\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJPofLLSqZsZv4bgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2afb26c128>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
